{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "\n",
    "from bsoup_scrape import bsoup_scrape_data\n",
    "from selenium_scrape import scrape_page2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "years = []\n",
    "episodes = []\n",
    "countries = []\n",
    "scores = []\n",
    "ranks = []\n",
    "\n",
    "titles_p2 = []\n",
    "genres = []\n",
    "network = []\n",
    "watchers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Beautiful Soup\n",
    "\n",
    "This section of code will use beautiful soup to scrape everything shown on the first page (the one listing all the titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to scrape\n",
    "url_base = 'https://mydramalist.com/shows/top?page='\n",
    "page_number = \"27\"\n",
    "url = url_base+page_number\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "bsoup_scrape_data(titles, years, episodes, countries, scores, ranks, soup)\n",
    "\n",
    "my_drama_list = pd.DataFrame({\n",
    "    \"title\": titles,\n",
    "    \"year\": years,\n",
    "    \"episodes\": episodes,\n",
    "    \"country\": countries,\n",
    "    \"viewer_score\": scores,\n",
    "    \"rank\": ranks\n",
    "})\n",
    "soup_scrape = pd.DataFrame(my_drama_list)\n",
    "\n",
    "#if the csv file already exists, delete it\n",
    "#if os.path.exists(\"msoup_scrapedl.csv\"):\n",
    "   #os.remove(\"soup_scrape.csv\")\n",
    "\n",
    "# soup_scrape.to_csv(\"combined_soup.csv\", index=False) #commenting this out so I don't accidentally delete it again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Selenium\n",
    "\n",
    "This section of the code will use selenium to click through each title page and scrape additional elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeout error- getting url\n",
      "It's Okay, That's Friendship\n",
      "Timeout error- clicking title \n",
      "No elements with 'original network' text found\n",
      "timeout error - going back\n",
      "The Princess's Man\n",
      "Timeout error- clicking title \n",
      "timeout error - going back\n",
      "Voice Season 2\n",
      "Timeout error- clicking title \n",
      "timeout error - going back\n",
      "Forever and Ever\n",
      "Timeout error- clicking title \n",
      "Liar Game 2\n",
      "Recipe for Farewell\n",
      "Timeout error- clicking title \n",
      "No elements with 'original network' text found\n",
      "Doom at Your Service\n",
      "Timeout error- clicking title \n",
      "timeout error - going back\n",
      "F4 Thailand: Boys Over Flowers\n",
      "Timeout error- clicking title \n",
      "Happy Birthday\n",
      "Timeout error- clicking title \n",
      "timeout error - going back\n",
      "Because This Is My First Life\n",
      "Timeout error- clicking title \n",
      "timeout error - going back\n",
      "Dali and the Cocky Prince\n",
      "Timeout error- clicking title \n",
      "timeout error - going back\n",
      "Lost\n",
      "Timeout error- clicking title \n",
      "timeout error - going back\n",
      "Seasons of Blossom\n",
      "Timeout error- clicking title \n",
      "No elements with 'original network' text found\n",
      "Koi wa Tsuzuku yo Doko Made mo\n",
      "timeout error - going back\n",
      "The Confidence Man JP\n",
      "Timeout error- clicking title \n",
      "timeout error - going back\n",
      "Kleun Cheewit\n",
      "timeout error - going back\n",
      "Lost Romance\n",
      "Timeout error- clicking title \n",
      "timeout error - going back\n",
      "Project S: Side by Side\n",
      "Crash Course in Romance\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://mydramalist.com/shows/top?page=15\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m scrape_page2(titles_p2, genres, watchers, network, url)\n\u001b[1;32m      4\u001b[0m selenium_scrape \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[1;32m      5\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m: titles_p2,\n\u001b[1;32m      6\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgenres\u001b[39m\u001b[39m\"\u001b[39m: genres,\n\u001b[1;32m      7\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mnetwork\u001b[39m\u001b[39m\"\u001b[39m: network,\n\u001b[1;32m      8\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwatchers\u001b[39m\u001b[39m\"\u001b[39m: watchers,\n\u001b[1;32m      9\u001b[0m })\n\u001b[1;32m     10\u001b[0m ss_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(selenium_scrape)\n",
      "File \u001b[0;32m~/Desktop/StatClasses/stat386/termProject/termProject/code/selenium_scrape.py:35\u001b[0m, in \u001b[0;36mscrape_page2\u001b[0;34m(titles, genres, watchers, network, url)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(title_elements), \u001b[39m2\u001b[39m):\n\u001b[1;32m     33\u001b[0m     \u001b[39m## re-find the element in each iteration\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     title_elements \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mfind_elements(By\u001b[39m.\u001b[39mCSS_SELECTOR, \u001b[39m'\u001b[39m\u001b[39mh6.title a\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m     element \u001b[39m=\u001b[39m title_elements[index]   \n\u001b[1;32m     36\u001b[0m     \u001b[39mprint\u001b[39m(element\u001b[39m.\u001b[39mtext)\n\u001b[1;32m     37\u001b[0m     titles\u001b[39m.\u001b[39mappend(element\u001b[39m.\u001b[39mtext)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "url = 'https://mydramalist.com/shows/top?page=15'\n",
    "scrape_page2(titles_p2, genres, watchers, network, url)\n",
    "\n",
    "selenium_scrape = pd.DataFrame({\n",
    "    \"title\": titles_p2,\n",
    "    \"genres\": genres,\n",
    "    \"network\": network,\n",
    "    \"watchers\": watchers,\n",
    "})\n",
    "ss_df = pd.DataFrame(selenium_scrape)\n",
    "ss_df\n",
    "\n",
    "ss_df.to_csv(\"deleteme.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging The DataFrames\n",
    "This section of the code will merge the csv files created from part 1 and part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV files\n",
    "import pandas as pd\n",
    "import os\n",
    "ss = pd.read_csv('combined_selenium.csv')\n",
    "ss19 = pd.read_csv('ss_df19.csv')\n",
    "ss20 = pd.read_csv('ss_df20.csv')\n",
    "ss21 = pd.read_csv('ss_df21.csv')\n",
    "ss22 = pd.read_csv('ss_df22.csv')\n",
    "ss23 = pd.read_csv('ss_df23.csv')\n",
    "ss24 = pd.read_csv('ss_df24.csv')\n",
    "ss25 = pd.read_csv('ss_df25.csv')\n",
    "ss26 = pd.read_csv('ss_df26.csv')\n",
    "\n",
    "\n",
    "# Combine the files\n",
    "selenium_mdl = pd.concat([ss, ss19, ss20, ss21, ss22, ss23, ss24,ss25,ss26])\n",
    "# if the csv file already exists, delete it\n",
    "if os.path.exists(\"combined_selenium.csv\"):\n",
    "    os.remove(\"combined_selenium.csv\")\n",
    "# Write the combined data to a new CSV file\n",
    "selenium_mdl.to_csv('combined_selenium.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge the selenium and beautiful soup csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = pd.read_csv('combined_soup.csv')\n",
    "sel = pd.read_csv('combined_selenium.csv')\n",
    "\n",
    "# Merge based on the 'title' column\n",
    "merged = pd.merge(soup, sel, on='title', how='inner') #'inner' keeps only matching rows\n",
    "\n",
    "# if the csv file already exists, delete it\n",
    "if os.path.exists(\"combined_mdl.csv\"):\n",
    "    os.remove(\"combined_mdl.csv\")\n",
    "\n",
    "# Write the merged data to a new CSV file\n",
    "merged.to_csv('combined_mdl.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polishing\n",
    "This section puts the finishing touches on the final csv file :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = pd.read_csv('combined_mdl.csv')\n",
    "test = mdl\n",
    "# clean up the network and genres column:\n",
    "with pd.option_context('mode.chained_assignment', None):\n",
    "    test['network'] = test['network'].str.split(': ').str[1]\n",
    "    test['genres'] = test['genres'].astype(str).str.replace(\", \", \",\")\n",
    "    test['genres'] = test['genres'].str.split(': ').str[1]\n",
    "    test['genres'] = test['genres'].astype(str).str.replace(\", \", \",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the genre and network are input as long strings. I am going to split them up into their own columns with a 1 or 0 if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all unique genres present in the df before splitting the column into separate columns\n",
    "unique_genres = set()\n",
    "for genres in test['genres']:\n",
    "    split_genres = genres.split(',')\n",
    "    for genre in split_genres:\n",
    "        unique_genres.add(genre)\n",
    "\n",
    "unique_network = set()\n",
    "for network in test['network']:\n",
    "    if pd.notnull(network) and network != 'na':  # Check for non-null and non-'na' values\n",
    "        split_network = network.split(',')\n",
    "        for option in split_network:\n",
    "            unique_network.add(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(unique_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating columns for each unique genre/network, put a zero if it's null/na\n",
    "with pd.option_context('mode.chained_assignment', None):\n",
    "    for genre in unique_genres:\n",
    "        test.loc[:, genre.strip()] = test['genres'].apply(lambda x: 1 if pd.notnull(x) and x != 'na' and genre in x else 0)\n",
    "    \n",
    "    for network in unique_network:\n",
    "        test.loc[:, network.strip()] = test['network'].apply(lambda x: 1 if pd.notnull(x) and x != 'na' and network in x else 0)\n",
    "\n",
    "    # Dropping the original 'genres' column\n",
    "    #test.drop('genres', axis=1, inplace=True)\n",
    "    #test.drop('network', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"mdl_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(523, 94)\n",
      "(523, 39)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "\n",
    "sums = test.iloc[:, 8:].sum(axis=0)\n",
    "# Get columns to drop where the sum is less than 2\n",
    "columns_to_drop = sums[sums < 16].index\n",
    "\n",
    "# Drop columns where the sum is less than 2\n",
    "test2 = test.drop(columns=columns_to_drop)\n",
    "print(test2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.to_csv(\"mdl_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hooray we made it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Crime', 'Sci-Fi', 'Wuxia', 'Youth', 'Medical', 'Psychological',\n",
       "       'Historical', 'Romance', 'Military', 'Music', 'Business', 'Thriller',\n",
       "       'Fantasy', 'Sports', 'Melodrama', 'Supernatural', 'Family', 'Tokusatsu',\n",
       "       'Law', 'Mystery', 'Adventure', 'Food', 'Horror', 'Life', 'Sitcom',\n",
       "       'Comedy', 'Political', 'Drama', 'Mature', 'Action', 'War'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "aaa = pd.read_csv('mdl_final.csv')\n",
    "aaa.columns[9:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Netflix</th>\n",
       "      <th>tvN</th>\n",
       "      <th>jTBC</th>\n",
       "      <th>TBS</th>\n",
       "      <th>JSTV</th>\n",
       "      <th>Viki</th>\n",
       "      <th>WeTV</th>\n",
       "      <th>TVK</th>\n",
       "      <th>GDTV</th>\n",
       "      <th>NTV</th>\n",
       "      <th>...</th>\n",
       "      <th>Channel A</th>\n",
       "      <th>Hulu</th>\n",
       "      <th>Disney+</th>\n",
       "      <th>TVING</th>\n",
       "      <th>TTV</th>\n",
       "      <th>MBN</th>\n",
       "      <th>iQiyi</th>\n",
       "      <th>GMM One</th>\n",
       "      <th>Fuji TV</th>\n",
       "      <th>BTV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>523 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Netflix  tvN  jTBC  TBS  JSTV  Viki  WeTV  TVK  GDTV  NTV  ...  \\\n",
       "0          0    1     0    0     0     0     0    0     0    0  ...   \n",
       "1          0    0     0    0     0     0     0    0     0    0  ...   \n",
       "2          0    0     0    0     0     0     0    0     0    0  ...   \n",
       "3          0    0     0    0     0     0     0    0     0    0  ...   \n",
       "4          0    1     0    0     0     0     0    0     0    0  ...   \n",
       "..       ...  ...   ...  ...   ...   ...   ...  ...   ...  ...  ...   \n",
       "518        0    0     0    0     0     0     0    0     0    1  ...   \n",
       "519        0    0     0    0     0     0     0    0     0    0  ...   \n",
       "520        0    0     0    0     0     0     0    0     0    1  ...   \n",
       "521        0    0     0    0     0     0     0    0     0    0  ...   \n",
       "522        0    0     0    0     0     0     0    0     0    0  ...   \n",
       "\n",
       "     Channel A  Hulu  Disney+  TVING  TTV  MBN  iQiyi  GMM One  Fuji TV  BTV  \n",
       "0            0     0        0      1    0    0      0        0        0    0  \n",
       "1            0     0        0      0    0    0      0        0        0    0  \n",
       "2            0     1        1      0    0    0      0        0        0    0  \n",
       "3            0     0        0      0    0    0      0        0        0    0  \n",
       "4            0     0        0      0    0    0      0        0        0    0  \n",
       "..         ...   ...      ...    ...  ...  ...    ...      ...      ...  ...  \n",
       "518          0     0        0      0    0    0      0        0        0    0  \n",
       "519          0     0        0      0    0    0      0        0        0    0  \n",
       "520          0     0        0      0    0    0      0        0        0    0  \n",
       "521          0     0        0      0    0    0      0        0        0    0  \n",
       "522          0     0        0      0    0    0      0        0        0    0  \n",
       "\n",
       "[523 rows x 54 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa.iloc[:, 40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daum Kakao TV     2\n",
      "WOWOW             3\n",
      "Tencent Video    19\n",
      "Dragon TV        11\n",
      "Amazon Prime      2\n",
      "ZJTV              7\n",
      "ENA               6\n",
      "PTS               1\n",
      "PPTV              1\n",
      "COUPANG TV        2\n",
      "ViuTV             8\n",
      "KBS2             27\n",
      "Mango TV         14\n",
      "CTV               9\n",
      "Youku            40\n",
      "SBS              38\n",
      "DRAMAcube         1\n",
      "GMM 25           14\n",
      "True4U            1\n",
      "OCN               2\n",
      "MBC              29\n",
      "Channel 3         4\n",
      "SET TV            1\n",
      "Sohu TV           1\n",
      "Channel A         1\n",
      "Hulu              7\n",
      "Disney+          12\n",
      "TVING            12\n",
      "TTV               1\n",
      "MBN               2\n",
      "iQiyi            53\n",
      "GMM One           5\n",
      "Fuji TV          19\n",
      "BTV               5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the sum of each column\n",
    "df = aaa.iloc[:, 60:]\n",
    "column_sums = df.sum()\n",
    "\n",
    "# Select column names that have a sum of at least 50\n",
    "selected_columns = column_sums[column_sums >= 15].index.tolist()\n",
    "\n",
    "\n",
    "print(column_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new386",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
